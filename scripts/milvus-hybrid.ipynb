{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587a81fb-9ef8-4f37-b00c-2b171a798b5d",
   "metadata": {},
   "source": [
    "## Hybrid Retrieval with Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7676b9ff-3c57-4afe-b877-16df103a27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Settings\n",
    "\n",
    " \n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "jinaai_api_key = os.environ.get(\"JINAAI_API_KEY\")\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "lgfuse_pub_key = os.environ.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "lgfuse_secret_key = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b07c4dba-4b7d-4f96-8ba8-4bc4ac807a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import CallbackManager\n",
    "from langfuse.llama_index import LlamaIndexCallbackHandler\n",
    "\n",
    "langfuse_callback_handler = LlamaIndexCallbackHandler(\n",
    "    public_key=lgfuse_pub_key,\n",
    "    secret_key=lgfuse_secret_key,\n",
    "    host=\"http://127.0.0.1:3000\"\n",
    ")\n",
    "Settings.callback_manager = CallbackManager([langfuse_callback_handler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4419935-dd09-41a3-947c-b8f96f230efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.jinaai import JinaEmbedding\n",
    "\n",
    "Settings.embed_model = JinaEmbedding(\n",
    "    api_key=jinaai_api_key,\n",
    "    #embed_batch_size=768,\n",
    "    model=\"jina-embeddings-v2-base-en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13af3d94-7631-49ae-8f23-1f9b2eb213a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizat/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "Settings.llm = Groq(model=\"llama3-70b-8192\", api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c554bf66-d5ef-4f38-a1e3-b277f45d52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 9149d9e2-4fe9-4b9e-b116-ad9904ad911e\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
    "\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d625917d-6b09-44d1-9dc8-d1293e12d577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse embedding function is not provided, using default.\n",
      "Fetching 30 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 310689.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an index over the documnts\n",
    "from llama_index.core import StorageContext\n",
    "import os\n",
    "\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri='http://127.0.0.1:19530',\n",
    "    dim=768,\n",
    "    overwrite=True,\n",
    "    enable_sparse=True,\n",
    "    hybrid_ranker=\"RRFRanker\",\n",
    "    hybrid_ranker_params={\"k\": 60},\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c36706-7bd1-4dcd-af0a-7ce81e204d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338aac4e-e890-4dc1-839e-bea1383215a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(vector_store_query_mode=\"hybrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6766f8-04e9-4258-ad04-215e15579f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author learned several things, including that low-end software tends to eat high-end software,\n",
      "that it's better for technology companies to be run by product people rather than sales people, that\n",
      "code edited by too many people leads to bugs, that cheap office space can be depressing, that\n",
      "planned meetings are inferior to corridor conversations, that big, bureaucratic customers can be a\n",
      "dangerous source of money, and that there's not much overlap between conventional office hours and\n",
      "the optimal time for hacking. The author also learned that being the \"entry-level\" option can be\n",
      "beneficial, and that prestige can be a danger sign.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author learn?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3d4365-d36d-484b-9f53-3601ef1ad393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hard moment for the author was when his mother had a stroke in the summer of 2012, caused by a\n",
      "blood clot from colon cancer, and he and his sister had to help her recover and get back to her\n",
      "house from the nursing home.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was a hard moment for the author?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e9ec8-703a-4db0-9c47-8794f1bab83e",
   "metadata": {},
   "source": [
    "## Custom Sparse-Encoding for Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f94db9-d51e-40c6-93ca-07f51aa1138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FlagEmbedding import BGEM3FlagModel\n",
    "#from typing import List\n",
    "#from llama_index.vector_stores.milvus.utils import BaseSparseEmbeddingFunction\n",
    "#\n",
    "#\n",
    "#class ExampleEmbeddingFunction(BaseSparseEmbeddingFunction):\n",
    "#    def __init__(self):\n",
    "#        self.model = BGEM3FlagModel(\"BAAI/bge-m3\", use_fp16=False)\n",
    "#\n",
    "#    def encode_queries(self, queries: List[str]):\n",
    "#        outputs = self.model.encode(\n",
    "#            queries,\n",
    "#            return_dense=False,\n",
    "#            return_sparse=True,\n",
    "#            return_colbert_vecs=False,\n",
    "#        )[\"lexical_weights\"]\n",
    "#        return [self._to_standard_dict(output) for output in outputs]\n",
    "#\n",
    "#    def encode_documents(self, documents: List[str]):\n",
    "#        outputs = self.model.encode(\n",
    "#            documents,\n",
    "#            return_dense=False,\n",
    "#            return_sparse=True,\n",
    "#            return_colbert_vecs=False,\n",
    "#        )[\"lexical_weights\"]\n",
    "#        return [self._to_standard_dict(output) for output in outputs]\n",
    "#\n",
    "#    def _to_standard_dict(self, raw_output):\n",
    "#        result = {}\n",
    "#        for k in raw_output:\n",
    "#            result[int(k)] = raw_output[k]\n",
    "#        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091de660-b219-458d-a8d0-7edb05703db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_store = MilvusVectorStore(\n",
    "#    dim=1536,\n",
    "#    overwrite=True,\n",
    "#    enable_sparse=True,\n",
    "#    sparse_embedding_function=ExampleEmbeddingFunction(),\n",
    "#    hybrid_ranker=\"RRFRanker\",\n",
    "#    hybrid_ranker_params={\"k\": 60},\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b75e35-daef-4ae4-af56-adda20eaaf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545cbc8-6e5e-4802-be85-4f8693463812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a6d6e-61c6-4971-bbf4-70e8d4001d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd97c54-be67-4854-b612-ce28889091f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a91b6-2d16-4af4-b171-1ed19571a528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef4a70-1d4b-4286-8295-fc1bdf8430ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
